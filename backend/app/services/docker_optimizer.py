import os
import json
import shutil
import subprocess
import uuid
from typing import Dict, Optional

from app.services.repo_handler import clone_repo_sparse


# --- Helpers for detection ---------------------------------------------------

def detect_project_type(cloned_dir: str) -> Dict:
    """
    Inspect the cloned_dir and return a dict describing what was found.
    keys:
      - has_dockerfile: bool
      - has_compose: bool
      - has_requirements: bool
      - has_package_json: bool
      - runtime: "python" | "node" | "unknown"
      - files: list of files present
    """
    files = []
    for root, _, filenames in os.walk(cloned_dir):
        # only inspect top-level to stay lean
        if root != cloned_dir:
            continue
        files.extend(filenames)

    has_dockerfile = "Dockerfile" in files
    has_compose = any(x in files for x in ["docker-compose.yml", "docker-compose.yaml"])
    has_requirements = "requirements.txt" in files or "pyproject.toml" in files or "Pipfile" in files
    has_package_json = "package.json" in files

    runtime = "unknown"
    if has_requirements:
        runtime = "python"
    elif has_package_json:
        runtime = "node"

    return {
        "has_dockerfile": has_dockerfile,
        "has_compose": has_compose,
        "has_requirements": has_requirements,
        "has_package_json": has_package_json,
        "runtime": runtime,
        "files": files
    }


# --- Dockerfile generation helpers ------------------------------------------

def generate_python_dockerfile(use_slim: bool = True) -> str:
    """
    A rule-based optimized Dockerfile for typical Python apps using requirements.txt.
    This is a single-file optimized Dockerfile (multi-stage not used here because many Python apps don't need build artifacts).
    """
    base = "python:3.11-slim" if use_slim else "python:3.11"
    return f"""# --- Optimized Dockerfile generated by DockMate ---
FROM {base} AS base

# Set working dir
WORKDIR /app

# Install system deps (if any required: git/build-essential) - keep minimal
RUN apt-get update && apt-get install -y --no-install-recommends \\
    build-essential \\
    && rm -rf /var/lib/apt/lists/*

# Copy only requirements first to leverage caching
COPY requirements.txt .

# Use pip's cache-less install to avoid larger images
RUN pip install --no-cache-dir -r requirements.txt

# Copy only source afterwards
COPY . .

# Use a non-root user for better security (optional)
RUN useradd -m dockmateuser && chown -R dockmateuser:docker /app
USER dockmateuser

# Expose common port (adjust if needed)
EXPOSE 8000

# Default command - try to be generic
CMD ["python", "main.py"]
"""


def generate_node_dockerfile() -> str:
    """
    Optimized Dockerfile for NodeJS apps (multi-stage build to reduce final size).
    """
    return """# --- Optimized Dockerfile generated by DockMate ---
# Build stage
FROM node:18-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci --silent
COPY . .
RUN npm run build || echo "no build step detected"

# Production stage
FROM node:18-alpine AS runtime
WORKDIR /app
COPY --from=build /app/package*.json ./
COPY --from=build /app/node_modules ./node_modules
COPY --from=build /app/dist ./dist
EXPOSE 3000
CMD ["node", "dist/index.js"]
"""


def generate_compose_stub(service_name: str = "app", image_tag: str = "dockmate/optimized:latest") -> str:
    return f"""version: "3.9"
services:
  {service_name}:
    image: {image_tag}
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
"""


def optimize_existing_dockerfile(content: str) -> str:
    """
    Simple rule-based 'optimizer' for an existing Dockerfile string.
    This is intentionally conservative: it aims to fix obvious inefficiencies:
      - switch to slim base if matching python image
      - move 'pip install' to use --no-cache-dir and copy requirements first
    For complex transformations you'd plug in AI or a Dockerfile parser.
    """
    # Very naive rules: try replace python:3.* with python:3.11-slim if found
    if "python:3" in content and "slim" not in content:
        content = content.replace("python:3", "python:3.11-slim")
    # ensure pip install uses --no-cache-dir
    content = content.replace("pip install ", "pip install --no-cache-dir ")
    # Return the modified content (could be identical)
    return "# --- Optimized (rule-based) version ---\n" + content


# --- Trivy + Docker build helpers -------------------------------------------

def safe_run(cmd: list, cwd: Optional[str] = None, timeout: int = 600) -> Dict:
    """
    Run subprocess and capture stdout/stderr. Return dict {ok, rc, out, err}
    """
    try:
        proc = subprocess.run(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=timeout)
        return {
            "ok": proc.returncode == 0,
            "rc": proc.returncode,
            "out": proc.stdout.decode(errors="replace"),
            "err": proc.stderr.decode(errors="replace"),
        }
    except Exception as e:
        return {"ok": False, "rc": -1, "out": "", "err": str(e)}


def build_docker_image(dockerfile_dir: str, tag: str) -> Dict:
    """
    Build docker image (requires docker daemon). Returns dict with success and logs.
    """
    cmd = ["docker", "build", "-t", tag, "."]
    return safe_run(cmd, cwd=dockerfile_dir)


def trivy_scan_image(tag: str) -> Dict:
    """
    Run trivy image scan and return JSON (if available) or textual report.
    Requires `trivy` CLI installed.
    """
    # prefer JSON output
    cmd = ["trivy", "image", "--format", "json", tag]
    return safe_run(cmd)


# --- Main service function --------------------------------------------------

def create_optimized_dockerfile_and_report(repo_url: str) -> Dict:
    """
    Main entrypoint:
      - sparse-clone important files
      - detect runtime/type
      - generate optimized Dockerfile (single step)
      - attempt docker build + trivy scan (if available)
      - return a dict that matches your artifacts table structure:
          {
            "dockerfile": "<text>",
            "report": { ... },  # JSON-serializable
            "ci_cd_instructions": "<text>",
            "workflow_file": "<text>"
          }
    """
    temp = None
    temp_image_tag = f"dockmate-temp:{uuid.uuid4().hex[:8]}"
    try:
        # 1) sparse clone
        clone_result = clone_repo_sparse(repo_url)
        temp = clone_result.get("cloned_dir")
        files = clone_result.get("files_collected", [])

        # 2) detect structure
        meta = detect_project_type(temp)

        # 3) Generate optimized Dockerfile directly
        dockerfile_text = None
        reasons = []

        if meta["has_dockerfile"]:
            # read existing Dockerfile and apply conservative optimizations
            existing_path = os.path.join(temp, "Dockerfile")
            try:
                with open(existing_path, "r", encoding="utf-8") as f:
                    existing = f.read()
                dockerfile_text = optimize_existing_dockerfile(existing)
                reasons.append("Optimized existing Dockerfile using rule-based tweaks.")
            except Exception as e:
                # fallback to generation by runtime
                reasons.append(f"Failed reading existing Dockerfile: {str(e)}")

        if not dockerfile_text:
            # generate based on runtime
            if meta["runtime"] == "python":
                dockerfile_text = generate_python_dockerfile()
                reasons.append("Generated optimized Python Dockerfile (requirements.txt detected).")
            elif meta["runtime"] == "node":
                dockerfile_text = generate_node_dockerfile()
                reasons.append("Generated optimized Node Dockerfile (package.json detected).")
            else:
                # fallback generic minimal Dockerfile
                dockerfile_text = """# Minimal optimized Dockerfile\nFROM alpine:3.18\nWORKDIR /app\nCOPY . .\nCMD [\"/bin/sh\"]\n"""
                reasons.append("Generated minimal fallback Dockerfile (unknown runtime).")

        # 4) create docker-compose stub if requested / detected
        compose_text = None
        if meta["has_compose"]:
            # if the repo already includes compose, read it and return as-is as "dockerfile" alternative
            compose_path = None
            for name in ("docker-compose.yml", "docker-compose.yaml"):
                p = os.path.join(temp, name)
                if os.path.exists(p):
                    compose_path = p
                    break
            if compose_path:
                try:
                    with open(compose_path, "r", encoding="utf-8") as f:
                        compose_text = f.read()
                        reasons.append("Found existing docker-compose.yml; returning it as compose artifact.")
                except Exception:
                    compose_text = generate_compose_stub()
                    reasons.append("Failed reading existing compose; generated a compose stub.")
        else:
            # If runtime detected, optionally provide a compose stub
            if meta["runtime"] in ("python", "node"):
                compose_text = generate_compose_stub()
                reasons.append("Generated docker-compose stub for convenience.")

        # 5) Optionally attempt build + trivy (best-effort)
        build_report = {"built": False, "build_log": "", "trivy": None}
        # Prepare a temp workspace with Dockerfile (so that build uses only required files)
        workspace_dir = None
        try:
            workspace_dir = os.path.join(temp, ".dockmate_workspace")
            os.makedirs(workspace_dir, exist_ok=True)
            # write Dockerfile
            dockerfile_path = os.path.join(workspace_dir, "Dockerfile")
            with open(dockerfile_path, "w", encoding="utf-8") as f:
                f.write(dockerfile_text)

            # copy minimal files needed for build (requirements.txt, package.json, etc.)
            for fname in ("requirements.txt", "package.json", "pyproject.toml", "Pipfile"):
                src = os.path.join(temp, fname)
                if os.path.exists(src):
                    shutil.copy2(src, workspace_dir)

            # attempt build
            build_res = build_docker_image(workspace_dir, temp_image_tag)
            build_report["build_log"] = build_res["out"] + "\n" + build_res["err"]
            if build_res["ok"]:
                build_report["built"] = True
                # run trivy
                trivy_res = trivy_scan_image(temp_image_tag)
                # trivy_res.out contains JSON when success
                if trivy_res["ok"] and trivy_res["out"]:
                    try:
                        build_report["trivy"] = json.loads(trivy_res["out"])
                    except Exception:
                        build_report["trivy_text"] = trivy_res["out"]
                else:
                    build_report["trivy_error"] = trivy_res["err"]
            else:
                build_report["build_error"] = build_res["err"]
        except Exception as e:
            build_report["error"] = str(e)
        finally:
            # remove workspace_dir
            try:
                if workspace_dir and os.path.exists(workspace_dir):
                    shutil.rmtree(workspace_dir)
            except Exception:
                pass

        # 6) Cleanup built image if exists
        if build_report.get("built"):
            safe_run(["docker", "rmi", "-f", temp_image_tag])

        # 7) Prepare artifact payload
        artifact = {
            "dockerfile": dockerfile_text if not compose_text else None,
            "docker_compose": compose_text,
            "report": {
                "meta": meta,
                "reasons": reasons,
                "build_report": build_report
            },
            "ci_cd_instructions": generate_ci_cd_instructions(meta),
            "workflow_file": generate_github_actions_workflow(meta)
        }

        return artifact

    except Exception as e:
        # Best effort cleanup
        if temp and os.path.exists(temp):
            try:
                shutil.rmtree(temp)
            except Exception:
                pass
        return {
            "error": str(e),
            "dockerfile": None,
            "report": {"error": str(e)}
        }
    finally:
        # Ensure temp clone removed
        if temp and os.path.exists(temp):
            try:
                shutil.rmtree(temp)
            except Exception:
                pass


# --- CI/CD helper generators (simple templates) --------------------------------

def generate_ci_cd_instructions(meta: Dict) -> str:
    """
    Return human-readable step-by-step CI/CD instructions for the user to follow.
    We keep it high-level and actionable; the UI can show this side-by-side with GitHub.
    """
    lines = []
    lines.append("1. Create a new branch in your repo (e.g., dockmate/add-dockerfile).")
    lines.append("2. Copy the generated optimized Dockerfile into the repo root as `Dockerfile`.")
    lines.append("3. (Optional) Add docker-compose.yml file if you want local compose support.")
    lines.append("4. Commit the files and push the branch.")
    lines.append("5. Create a Pull Request on GitHub from your branch to main.")
    lines.append("6. In your GitHub repo, go to Settings -> Secrets -> New repository secret and add any required secrets (e.g., REGISTRY_USERNAME, REGISTRY_PASSWORD).")
    lines.append("7. Merge the PR. GitHub Actions will run the workflow to build and push the Docker image (if you used the workflow).")
    if meta.get("runtime") == "python":
        lines.append("Notes: The Dockerfile expects `requirements.txt` at repo root. If your app entrypoint is not `main.py`, update the CMD accordingly.")
    if meta.get("runtime") == "node":
        lines.append("Notes: The workflow expects a `build` script or `dist/index.js`. Adjust the workflow if your start script differs.")
    return "\n".join(lines)


def generate_github_actions_workflow(meta: Dict) -> str:
    """
    Return a basic GitHub Actions workflow that tests (if tests exist) and builds+pushes Docker image.
    It's generic; users should add repo secrets for registry.
    """
    # Simple workflow template
    workflow = {
        "name": "CI - Build and (optional) Push",
        "on": ["push", "pull_request"],
        "jobs": {
            "build": {
                "runs-on": "ubuntu-latest",
                "steps": [
                    {"name": "Checkout", "uses": "actions/checkout@v4"},
                    {"name": "Set up QEMU", "uses": "docker/setup-qemu-action@v2"},
                    {"name": "Set up Docker Buildx", "uses": "docker/setup-buildx-action@v2"},
                ]
            }
        }
    }

    # Add steps depending on runtime
    steps = workflow["jobs"]["build"]["steps"]
    if meta.get("runtime") == "python":
        steps.append({"name": "Install Python", "uses": "actions/setup-python@v4", "with": {"python-version": "3.11"}})
        steps.append({"name": "Build and load image", "run": "docker build -t ${{ github.repository }}:${{ github.sha }} ."})
    elif meta.get("runtime") == "node":
        steps.append({"name": "Install Node", "uses": "actions/setup-node@v4", "with": {"node-version": "18"}})
        steps.append({"name": "Build and load image", "run": "docker build -t ${{ github.repository }}:${{ github.sha }} ."})
    else:
        steps.append({"name": "Build and load image", "run": "docker build -t ${{ github.repository }}:${{ github.sha }} ."})

    # Convert to YAML-like text (we'll create a minimal YAML string)
    # Simpler to return a hand-crafted YAML string for clarity:
    yaml = f"""name: CI - Build and (optional) Push
on: [push, pull_request]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v2
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
"""
    if meta.get("runtime") == "python":
        yaml += """      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11
      - name: Build image
        run: docker build -t ${{ github.repository }}:${{ github.sha }} .
"""
    elif meta.get("runtime") == "node":
        yaml += """      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: 18
      - name: Build image
        run: docker build -t ${{ github.repository }}:${{ github.sha }} .
"""
    else:
        yaml += """      - name: Build image
        run: docker build -t ${{ github.repository }}:${{ github.sha }} .
"""

    yaml += """      - name: (Optional) Push image
        if: github.event_name == 'push'
        run: |
          echo "Add push steps here (use secrets.REGISTRY_USERNAME and secrets.REGISTRY_PASSWORD)"
"""

    return yaml

